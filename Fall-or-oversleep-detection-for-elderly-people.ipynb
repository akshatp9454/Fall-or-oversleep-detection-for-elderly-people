{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7082436",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afcce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL # image library in python\n",
    "import tensorflow as tf\n",
    "from skimage.io import imread,imshow\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe6539b",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fall - Train\n",
    "fall_train = []\n",
    "for dirname, _, filenames in os.walk('FALL-vs-NORMAL/FALL/train'):\n",
    "    for filename in filenames:\n",
    "        fall_train.append(os.path.join(dirname, filename))\n",
    "\n",
    "fall_train_count = len(fall_train)\n",
    "print(fall_train_count)\n",
    "print(fall_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fall - Val\n",
    "fall_val = []\n",
    "for dirname, _, filenames in os.walk('FALL-vs-NORMAL/FALL/val'):\n",
    "    for filename in filenames:\n",
    "        fall_val.append(os.path.join(dirname, filename))\n",
    "\n",
    "fall_val_count = len(fall_val)\n",
    "print(fall_val_count)\n",
    "print(fall_val[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal - Train\n",
    "normal_train = []\n",
    "for dirname, _, filenames in os.walk('FALL-vs-NORMAL/NORMAL/train'):\n",
    "    for filename in filenames:\n",
    "        normal_train.append(os.path.join(dirname, filename))\n",
    "\n",
    "normal_train_count = len(normal_train)\n",
    "print(normal_train_count)\n",
    "print(normal_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal - Val\n",
    "normal_val = []\n",
    "for dirname, _, filenames in os.walk('FALL-vs-NORMAL/NORMAL/val'):\n",
    "    for filename in filenames:\n",
    "        normal_val.append(os.path.join(dirname, filename))\n",
    "\n",
    "normal_val_count = len(normal_val)\n",
    "print(normal_val_count)\n",
    "print(normal_val[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfc253",
   "metadata": {},
   "source": [
    "## View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dccf9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(fall_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426f6b4a",
   "metadata": {},
   "source": [
    "## Creating dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96474710",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\n",
    "    'fall' : fall_train,\n",
    "    'normal' : normal_train\n",
    "}\n",
    "\n",
    "val_dict = {\n",
    "    'fall' : fall_val,\n",
    "    'normal' : normal_val\n",
    "}\n",
    "\n",
    "class_dict = {\n",
    "    'fall' : 1,\n",
    "    'normal' : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a8d34",
   "metadata": {},
   "source": [
    "## Preparing data as arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556dca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for class_name, images in train_dict.items():\n",
    "    for image in images:\n",
    "      img = cv2.imread(image)\n",
    "      resized_img = cv2.resize(img,(128,128))\n",
    "      x_train.append(resized_img)\n",
    "      y_train.append(class_dict[class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229cc2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "x_val, y_val = [], []\n",
    "\n",
    "for class_name, images in val_dict.items():\n",
    "    for image in images:\n",
    "      img = cv2.imread(image)\n",
    "      resized_img = cv2.resize(img,(128,128))\n",
    "      x_val.append(resized_img)\n",
    "      y_val.append(class_dict[class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19605d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list into numpy array for simpler further use\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d726a2c",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3502261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = x_train / 255\n",
    "x_val_scaled = x_val / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051b09b",
   "metadata": {},
   "source": [
    "## Number of training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7027a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training images: \",len(x_train_scaled))\n",
    "print(\"Training labels: \",len(y_train))\n",
    "print()\n",
    "print(\"Validation images: \",len(x_val_scaled))\n",
    "print(\"Validation labels: \",len(y_val))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e56a1",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1bb762",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomZoom(0.3), \n",
    "    layers.experimental.preprocessing.RandomContrast(0.3),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccd54a",
   "metadata": {},
   "source": [
    "## Creating CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5b118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "\n",
    "model = Sequential([\n",
    "                   data_augmentation, \n",
    "                   layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "                   layers.MaxPooling2D(),\n",
    "                   layers.Dropout(0.1),\n",
    "                   layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "                   layers.MaxPooling2D(),\n",
    "                   layers.Dropout(0.1),\n",
    "                   layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "                   layers.MaxPooling2D(),\n",
    "                   layers.Dropout(0.1), # going to drop 10% of neurons at random in each pass to give us better generalization\n",
    "                   layers.Flatten(),\n",
    "                   layers.Dense(128,activation='relu'),\n",
    "                   layers.Dense(num_classes, activation='sigmoid')\n",
    "                  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "np.random.seed(42)\n",
    "from keras import callbacks\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 3, \n",
    "                                        restore_best_weights = True)\n",
    "  \n",
    "history = model.fit(x_train_scaled, y_train, batch_size = 64, \n",
    "                    epochs = 100, validation_data =(x_val_scaled, y_val), \n",
    "                    callbacks =[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ea9c4",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ec12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_val_scaled,y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e66c2e5",
   "metadata": {},
   "source": [
    "## Saving model with best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe98a2",
   "metadata": {},
   "source": [
    "## Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b178d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "from tensorflow import keras\n",
    "load_model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f2ffc",
   "metadata": {},
   "source": [
    "## Prediction on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e112e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = load_model.predict(x_val_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c55686",
   "metadata": {},
   "source": [
    "## Evaluation metrics - validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ca244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Source code credit for this function: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('Truth')\n",
    "    plt.xlabel('Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3053d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = y_val.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6289f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "\n",
    "for i in range(0,len(predictions)):\n",
    "    score = tf.nn.softmax(predictions[i])\n",
    "    pred_list.append(np.argmax(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eecc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the validation results\n",
    "cm = confusion_matrix(truth,pred_list)\n",
    "print_confusion_matrix(cm,[\"Not a Fall\",\"Fall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef9155",
   "metadata": {},
   "source": [
    "## Code to detect fall or oversleep from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(num):\n",
    "    if num == 0:\n",
    "        return \"no fall\"\n",
    "    elif num == 1:\n",
    "        return \"fall\"\n",
    "    elif num == 2:\n",
    "        return \"overtime sleep\"\n",
    "    \n",
    "def demo_func(filename):\n",
    "    # load model\n",
    "    load_model = keras.models.load_model('model.h5')\n",
    "\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fc = 0\n",
    "    ret = True\n",
    "    pfp = 0\n",
    "    th = 30\n",
    "    th_z = 700\n",
    "    count = 0 \n",
    "    zeros = 0\n",
    "    track = 0\n",
    "\n",
    "    n=1\n",
    "    test_pred = []\n",
    "    print(frameCount)\n",
    "    while (fc < frameCount):\n",
    "\n",
    "        ret, image = cap.read()\n",
    "        if (fc % 30 == 0):\n",
    "            rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            plt.imshow(rgb_img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            img_scaled = rgb_img / 255\n",
    "            r_img = cv2.resize(img_scaled,(128,128))\n",
    "            x = np.expand_dims(r_img, axis=0)\n",
    "            prediction = load_model.predict(x)\n",
    "            score = tf.nn.softmax(prediction)\n",
    "            cfp = np.argmax(score) #current frame prediction\n",
    "            test_pred.append(cfp)\n",
    "            print(n,\" : \",cfp)\n",
    "            n+=1\n",
    "            if (cfp == 1):\n",
    "                if pfp == 0:\n",
    "                    count = 0\n",
    "                else:\n",
    "                    count+=1\n",
    "            elif (cfp == 0):\n",
    "                if pfp == 1:\n",
    "                    zeros = 0\n",
    "                else:\n",
    "                    zeros+=1\n",
    "            if (count == th):\n",
    "                #print(\"!!! FALL DETECTED !!!\")\n",
    "                output = classify(1)\n",
    "                break\n",
    "            if (zeros == th_z):\n",
    "                #print(\"!!! OVERTIME SLEEP !!!\")\n",
    "                output = classify(2)\n",
    "                break\n",
    "            pfp = cfp\n",
    "        fc += 1\n",
    "    if(count != th and zeros != th_z):\n",
    "        #print(\"!!! Fall NOT Detected OR Normal Sleep !!!\")\n",
    "        output = classify(0)\n",
    "    \n",
    "    \n",
    "\n",
    "    if output == \"no fall\":\n",
    "        return [(0,output)]\n",
    "    elif output == \"fall\":\n",
    "        return [(1,output)]\n",
    "    else :\n",
    "        return [(2,output)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f64858d",
   "metadata": {},
   "source": [
    "## User interface with gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f405fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "op = gr.outputs.HighlightedText(color_map={ \"no fall\":\"green\",\"fall\":\"red\",\"overtime sleep\":\"yellow\" })\n",
    "demo = gr.Interface(demo_func, gr.Video(), outputs = op, live =True)\n",
    "demo.launch(debug=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
